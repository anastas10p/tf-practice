{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Building a Convolutional Neural Network in TensorFlow 2.0 .ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRHFdNYAfWKJ"
   },
   "source": [
    "## Part 0: Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tS5xFeQwe9Xu",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "9aacd236-4553-4a05-999d-aca4b83913b1"
   },
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "tf.__version__"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.6.2'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8zYubaPfy-S"
   },
   "source": [
    "## Part 1: Data preprocessing\n",
    "\n",
    "### Load the Cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f13-8-m_fqKP",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "outputId": "f782a5f1-7778-4138-c647-877b2d48e878"
   },
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#Setting class names for the output\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqDIpsJWgUkz"
   },
   "source": [
    "### Image normalization\n",
    "\n",
    "Just like with fashion_MNIST, each datapoint is divided by the number of pixels"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-QFncPlpgNmU"
   },
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is no need to reshape the data this time, since it is fed to a CNN."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L1rFHX67gc6G",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "5342e459-6431-4e70-c7c9-6dd332bb650c"
   },
   "source": [
    "X_train.shape"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(50000, 32, 32, 3)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see an image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7jwvNZ82gh9d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "outputId": "db6d0be2-de1f-4c2b-8b8d-c4aaba462b62"
   },
   "source": [
    "plt.imshow(X_test[106])"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fce7d93f5f8>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXiuZulIguyf"
   },
   "source": [
    "## Part 2: Build the Convolutional neural network\n",
    "### Defining the model\n",
    "\n",
    "Here, a convolutional neural network is used. It is still a Sequential model.\n",
    "The model consists of two parts: a convolutional and a \"simple\" one.\n",
    "The convolutional part uses convolutional and max pooling layers, and the simple part uses only dense layers.\n",
    "To transition between the two parts, the tensors are flattened using a flattening layer."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1TR0JGP5gq2i"
   },
   "source": [
    "model = tf.keras.models.Sequential()"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j92d4FE0hTZV"
   },
   "source": [
    "### First Layer (Convolutional)\n",
    "\n",
    "CNN layer hyper-parameters:\n",
    "- filters: 32 the number of convolutions used\n",
    "- kernel_size:3 the kernel size of each filter\n",
    "- activation function: relu\n",
    "- input_shape: (32, 32, 3) Images of 32 by 32 pixels of 3 channels\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LSkL1iOvg_dE"
   },
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=[32, 32, 3]))"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfRAaRmWiSlZ"
   },
   "source": [
    "### The second convolutional layer\n",
    "\n",
    "CNN layer hyper-parameters:\n",
    "- filters: 32\n",
    "- kernel_size:3\n",
    "- padding: same\n",
    "- activation function: relu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sSl7Es5yidMp"
   },
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"))"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The max pooling layer\n",
    "MaxPool layer hyper-parameters:\n",
    "- pool_size: 2\n",
    "- strides: 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wmP9h5wliAR6"
   },
   "source": [
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wd8ERDyvin-0"
   },
   "source": [
    "### The third layer\n",
    "\n",
    "CNN layer hyper-parameters:\n",
    "\n",
    "-    filters: 64\n",
    " -   kernel_size:3\n",
    "  -  activation: relu"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i9HWy6aFixEw"
   },
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\"))"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O55kyOQGi44V"
   },
   "source": [
    "###  The fourth CNN Layer and the second max pool layer\n",
    "\n",
    "CNN layer hyper-parameters:\n",
    "\n",
    "-    filters: 64\n",
    " -   kernel_size:3\n",
    "  -  activation: relu\n",
    "\n",
    "MaxPool layer hyper-parameters:\n",
    "\n",
    "   - pool_size: 2\n",
    "   - strides: 2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5b7vAuhjjCF2"
   },
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hGnR3aXjKbZ"
   },
   "source": [
    "### The Flatten layer\n",
    "\n",
    "The flatten layer flattens its tensor input to a vector."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QLzu2cCVjI5Z"
   },
   "source": [
    "model.add(tf.keras.layers.Flatten())"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpeRUvVWjR1W"
   },
   "source": [
    "### Add the first Dense layer\n",
    "\n",
    "Once the convolutional part of the network is done, the data is flattened and fed to the dense part of the network.\n",
    "Dense layer hyper-parameters:\n",
    "- neurons: 128\n",
    "- activation: relu"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FWzYY8kKjhnZ"
   },
   "source": [
    "model.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaakKTqRjrkF"
   },
   "source": [
    "### Adding the output layer (Dense)\n",
    "\n",
    "Dense layer hyper-parameters:\n",
    "\n",
    " - units/neurons: 10 (number of classes)\n",
    " - activation: softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4t-JmzRvjnBj"
   },
   "source": [
    "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Show the model's architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aRr3bCU-ti06",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "outputId": "8c18a1c8-5607-4b12-c549-787e721e4a6f"
   },
   "source": [
    "model.summary()"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 361,898\n",
      "Trainable params: 361,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYgvbNihtprw"
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "- Optimizer: Adam\n",
    "- Loss function: Sparse softmax (categorical) crossentropy\n",
    "\n",
    "Similar to the fashion MNIST model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oYHELxz4tsa-"
   },
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"Adam\", metrics=[\"sparse_categorical_accuracy\"])"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gox3SmwUtwgX"
   },
   "source": [
    "## Part 3: Train the model\n",
    "\n",
    "#### Again, only 5 epochs, since achieving accuracy is not the purpose of these exercises"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "D3MHvRYKe9fN",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "outputId": "39dbc848-9a88-4663-a09b-f7469a25b9b4"
   },
   "source": [
    "model.fit(X_train, y_train, epochs=3)"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 176s 111ms/step - loss: 1.4010 - sparse_categorical_accuracy: 0.4934\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 190s 121ms/step - loss: 0.9524 - sparse_categorical_accuracy: 0.6657\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 189s 121ms/step - loss: 0.7758 - sparse_categorical_accuracy: 0.7282\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fcd91713b00>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8C7Pm0NuOrJ"
   },
   "source": [
    "### Evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z9r8TtNet3D0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "c09abc05-5b1b-4208-f654-09c24c9914d8"
   },
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy: {}\".format(test_accuracy))"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 11s 34ms/step - loss: 0.7895 - sparse_categorical_accuracy: 0.7240\n",
      "Test accuracy: 0.7239999771118164\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSKfLqi5urEh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 4: Save the model\n",
    "\n",
    "### Save the architecture of the network as .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"02_cifar10_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the network weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "model.save_weights(\"02_cifar10_model.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}